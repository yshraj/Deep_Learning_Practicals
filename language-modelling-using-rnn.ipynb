{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom keras.models import Sequential\nfrom keras.layers import SimpleRNN, Dense, Embedding\n\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T06:13:25.419900Z","iopub.execute_input":"2022-05-05T06:13:25.420305Z","iopub.status.idle":"2022-05-05T06:13:25.426216Z","shell.execute_reply.started":"2022-05-05T06:13:25.420267Z","shell.execute_reply":"2022-05-05T06:13:25.425509Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"\ndata = \"\"\"Once there was a dog.\\nOne day, he found a big juicy bone.\nDog immediately grabbed it between his mouth and took it home.\nOn his way home, he crossed a river.\nThat night, he went home hungry.\"\"\"\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:26.191511Z","iopub.execute_input":"2022-05-05T06:13:26.192127Z","iopub.status.idle":"2022-05-05T06:13:26.196632Z","shell.execute_reply.started":"2022-05-05T06:13:26.192091Z","shell.execute_reply":"2022-05-05T06:13:26.195895Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Once there was a dog.\nOne day, he found a big juicy bone.\nDog immediately grabbed it between his mouth and took it home.\nOn his way home, he crossed a river.\nThat night, he went home hungry.\n","output_type":"stream"}]},{"cell_type":"code","source":"data_splitted = data.split('\\n')\ndata_splitted","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:26.968842Z","iopub.execute_input":"2022-05-05T06:13:26.969358Z","iopub.status.idle":"2022-05-05T06:13:26.975012Z","shell.execute_reply.started":"2022-05-05T06:13:26.969318Z","shell.execute_reply":"2022-05-05T06:13:26.974055Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"['Once there was a dog.',\n 'One day, he found a big juicy bone.',\n 'Dog immediately grabbed it between his mouth and took it home.',\n 'On his way home, he crossed a river.',\n 'That night, he went home hungry.']"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = Tokenizer(filters='!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~')\n\n# Initializing vocabulary\ntokenizer.fit_on_texts(data_splitted)\nprint(tokenizer.word_index)\n\nvocab_length = len(tokenizer.word_index) + 1\nvocab_length","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:27.445145Z","iopub.execute_input":"2022-05-05T06:13:27.446050Z","iopub.status.idle":"2022-05-05T06:13:27.456127Z","shell.execute_reply.started":"2022-05-05T06:13:27.446008Z","shell.execute_reply":"2022-05-05T06:13:27.455384Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"{'a': 1, 'he': 2, 'it': 3, 'his': 4, 'home': 5, 'once': 6, 'there': 7, 'was': 8, 'dog.': 9, 'one': 10, 'day': 11, 'found': 12, 'big': 13, 'juicy': 14, 'bone.': 15, 'dog': 16, 'immediately': 17, 'grabbed': 18, 'between': 19, 'mouth': 20, 'and': 21, 'took': 22, 'home.': 23, 'on': 24, 'way': 25, 'crossed': 26, 'river.': 27, 'that': 28, 'night': 29, 'went': 30, 'hungry.': 31}\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"32"},"metadata":{}}]},{"cell_type":"code","source":"sequences = tokenizer.texts_to_sequences(data_splitted)\nsequences","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:28.090918Z","iopub.execute_input":"2022-05-05T06:13:28.091160Z","iopub.status.idle":"2022-05-05T06:13:28.099288Z","shell.execute_reply.started":"2022-05-05T06:13:28.091133Z","shell.execute_reply":"2022-05-05T06:13:28.098346Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"[[6, 7, 8, 1, 9],\n [10, 11, 2, 12, 1, 13, 14, 15],\n [16, 17, 18, 3, 19, 4, 20, 21, 22, 3, 23],\n [24, 4, 25, 5, 2, 26, 1, 27],\n [28, 29, 2, 30, 5, 31]]"},"metadata":{}}]},{"cell_type":"code","source":"X = []\ny = []\n\nfor i in range(len(sequences)):\n  X.append(sequences[i][:-1])\n\ny = sequences\n\nprint(X)\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:28.422869Z","iopub.execute_input":"2022-05-05T06:13:28.423098Z","iopub.status.idle":"2022-05-05T06:13:28.428938Z","shell.execute_reply.started":"2022-05-05T06:13:28.423070Z","shell.execute_reply":"2022-05-05T06:13:28.428142Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"[[6, 7, 8, 1], [10, 11, 2, 12, 1, 13, 14], [16, 17, 18, 3, 19, 4, 20, 21, 22, 3], [24, 4, 25, 5, 2, 26, 1], [28, 29, 2, 30, 5]]\n[[6, 7, 8, 1, 9], [10, 11, 2, 12, 1, 13, 14, 15], [16, 17, 18, 3, 19, 4, 20, 21, 22, 3, 23], [24, 4, 25, 5, 2, 26, 1, 27], [28, 29, 2, 30, 5, 31]]\n","output_type":"stream"}]},{"cell_type":"code","source":"for x in X:\n  x.insert(0,0)\n\nfor op in y:\n  op.insert(0,0)\n\nX\ny","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:28.679389Z","iopub.execute_input":"2022-05-05T06:13:28.679818Z","iopub.status.idle":"2022-05-05T06:13:28.687792Z","shell.execute_reply.started":"2022-05-05T06:13:28.679788Z","shell.execute_reply":"2022-05-05T06:13:28.686264Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"[[0, 6, 7, 8, 1, 9],\n [0, 10, 11, 2, 12, 1, 13, 14, 15],\n [0, 16, 17, 18, 3, 19, 4, 20, 21, 22, 3, 23],\n [0, 24, 4, 25, 5, 2, 26, 1, 27],\n [0, 28, 29, 2, 30, 5, 31]]"},"metadata":{}}]},{"cell_type":"code","source":"# finding the max length of input sequences\nmax_len = 0; \nfor x in X:\n  max_len = max(max_len,len(x))\n\nmax_len","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:28.918531Z","iopub.execute_input":"2022-05-05T06:13:28.918724Z","iopub.status.idle":"2022-05-05T06:13:28.923916Z","shell.execute_reply.started":"2022-05-05T06:13:28.918700Z","shell.execute_reply":"2022-05-05T06:13:28.923156Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"11"},"metadata":{}}]},{"cell_type":"code","source":"X = pad_sequences(X,max_len,padding='pre')\nX","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:30.579907Z","iopub.execute_input":"2022-05-05T06:13:30.581993Z","iopub.status.idle":"2022-05-05T06:13:30.588213Z","shell.execute_reply.started":"2022-05-05T06:13:30.581955Z","shell.execute_reply":"2022-05-05T06:13:30.587320Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"array([[ 0,  0,  0,  0,  0,  0,  0,  6,  7,  8,  1],\n       [ 0,  0,  0,  0, 10, 11,  2, 12,  1, 13, 14],\n       [ 0, 16, 17, 18,  3, 19,  4, 20, 21, 22,  3],\n       [ 0,  0,  0,  0, 24,  4, 25,  5,  2, 26,  1],\n       [ 0,  0,  0,  0,  0,  0, 28, 29,  2, 30,  5]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"y = pad_sequences(y,max_len,padding='pre')\ny","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:31.306044Z","iopub.execute_input":"2022-05-05T06:13:31.306623Z","iopub.status.idle":"2022-05-05T06:13:31.313056Z","shell.execute_reply.started":"2022-05-05T06:13:31.306585Z","shell.execute_reply":"2022-05-05T06:13:31.312350Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"array([[ 0,  0,  0,  0,  0,  0,  6,  7,  8,  1,  9],\n       [ 0,  0,  0, 10, 11,  2, 12,  1, 13, 14, 15],\n       [16, 17, 18,  3, 19,  4, 20, 21, 22,  3, 23],\n       [ 0,  0,  0, 24,  4, 25,  5,  2, 26,  1, 27],\n       [ 0,  0,  0,  0,  0, 28, 29,  2, 30,  5, 31]], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"y = to_categorical(y,num_classes = vocab_length)\ny","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:32.358169Z","iopub.execute_input":"2022-05-05T06:13:32.358876Z","iopub.status.idle":"2022-05-05T06:13:32.368970Z","shell.execute_reply.started":"2022-05-05T06:13:32.358827Z","shell.execute_reply":"2022-05-05T06:13:32.368174Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"array([[[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        [1., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 1., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 1.]]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"y.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:32.702814Z","iopub.execute_input":"2022-05-05T06:13:32.703265Z","iopub.status.idle":"2022-05-05T06:13:32.708841Z","shell.execute_reply.started":"2022-05-05T06:13:32.703228Z","shell.execute_reply":"2022-05-05T06:13:32.707965Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"(5, 11, 32)"},"metadata":{}}]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(input_dim=vocab_length, output_dim=10))\nmodel.add(SimpleRNN(50,return_sequences=True))\nmodel.add(Dense(units=vocab_length, activation='softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:32.934151Z","iopub.execute_input":"2022-05-05T06:13:32.934426Z","iopub.status.idle":"2022-05-05T06:13:33.010654Z","shell.execute_reply.started":"2022-05-05T06:13:32.934384Z","shell.execute_reply":"2022-05-05T06:13:33.009797Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, None, 10)          320       \n_________________________________________________________________\nsimple_rnn_2 (SimpleRNN)     (None, None, 50)          3050      \n_________________________________________________________________\ndense_2 (Dense)              (None, None, 32)          1632      \n=================================================================\nTotal params: 5,002\nTrainable params: 5,002\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit(X,y,epochs=200)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:33.190992Z","iopub.execute_input":"2022-05-05T06:13:33.191255Z","iopub.status.idle":"2022-05-05T06:13:37.605289Z","shell.execute_reply.started":"2022-05-05T06:13:33.191218Z","shell.execute_reply":"2022-05-05T06:13:37.604606Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"Epoch 1/200\n1/1 [==============================] - 1s 797ms/step - loss: 3.4779 - accuracy: 0.0182\nEpoch 2/200\n1/1 [==============================] - 0s 14ms/step - loss: 3.4663 - accuracy: 0.0182\nEpoch 3/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.4552 - accuracy: 0.0182\nEpoch 4/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.4441 - accuracy: 0.0364\nEpoch 5/200\n1/1 [==============================] - 0s 14ms/step - loss: 3.4330 - accuracy: 0.0364\nEpoch 6/200\n1/1 [==============================] - 0s 13ms/step - loss: 3.4215 - accuracy: 0.0727\nEpoch 7/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.4095 - accuracy: 0.1091\nEpoch 8/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.3968 - accuracy: 0.2545\nEpoch 9/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.3832 - accuracy: 0.2545\nEpoch 10/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.3685 - accuracy: 0.2545\nEpoch 11/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.3525 - accuracy: 0.2545\nEpoch 12/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.3352 - accuracy: 0.3273\nEpoch 13/200\n1/1 [==============================] - 0s 14ms/step - loss: 3.3165 - accuracy: 0.3455\nEpoch 14/200\n1/1 [==============================] - 0s 14ms/step - loss: 3.2964 - accuracy: 0.3273\nEpoch 15/200\n1/1 [==============================] - 0s 13ms/step - loss: 3.2753 - accuracy: 0.3273\nEpoch 16/200\n1/1 [==============================] - 0s 14ms/step - loss: 3.2533 - accuracy: 0.3273\nEpoch 17/200\n1/1 [==============================] - 0s 15ms/step - loss: 3.2307 - accuracy: 0.3273\nEpoch 18/200\n1/1 [==============================] - 0s 15ms/step - loss: 3.2078 - accuracy: 0.3273\nEpoch 19/200\n1/1 [==============================] - 0s 15ms/step - loss: 3.1846 - accuracy: 0.3273\nEpoch 20/200\n1/1 [==============================] - 0s 15ms/step - loss: 3.1611 - accuracy: 0.3273\nEpoch 21/200\n1/1 [==============================] - 0s 13ms/step - loss: 3.1372 - accuracy: 0.3273\nEpoch 22/200\n1/1 [==============================] - 0s 15ms/step - loss: 3.1127 - accuracy: 0.3455\nEpoch 23/200\n1/1 [==============================] - 0s 15ms/step - loss: 3.0876 - accuracy: 0.3455\nEpoch 24/200\n1/1 [==============================] - 0s 15ms/step - loss: 3.0617 - accuracy: 0.3455\nEpoch 25/200\n1/1 [==============================] - 0s 12ms/step - loss: 3.0351 - accuracy: 0.3818\nEpoch 26/200\n1/1 [==============================] - 0s 15ms/step - loss: 3.0077 - accuracy: 0.4000\nEpoch 27/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.9797 - accuracy: 0.4182\nEpoch 28/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.9513 - accuracy: 0.4364\nEpoch 29/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.9226 - accuracy: 0.4000\nEpoch 30/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.8936 - accuracy: 0.3818\nEpoch 31/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.8644 - accuracy: 0.4000\nEpoch 32/200\n1/1 [==============================] - 0s 13ms/step - loss: 2.8351 - accuracy: 0.3818\nEpoch 33/200\n1/1 [==============================] - 0s 16ms/step - loss: 2.8057 - accuracy: 0.3818\nEpoch 34/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.7761 - accuracy: 0.3818\nEpoch 35/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.7466 - accuracy: 0.4000\nEpoch 36/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.7170 - accuracy: 0.4000\nEpoch 37/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.6874 - accuracy: 0.4000\nEpoch 38/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.6580 - accuracy: 0.4000\nEpoch 39/200\n1/1 [==============================] - 0s 17ms/step - loss: 2.6286 - accuracy: 0.4000\nEpoch 40/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.5995 - accuracy: 0.4364\nEpoch 41/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.5706 - accuracy: 0.4364\nEpoch 42/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.5419 - accuracy: 0.4364\nEpoch 43/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.5135 - accuracy: 0.4364\nEpoch 44/200\n1/1 [==============================] - 0s 16ms/step - loss: 2.4852 - accuracy: 0.4545\nEpoch 45/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.4571 - accuracy: 0.4727\nEpoch 46/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.4291 - accuracy: 0.4909\nEpoch 47/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.4012 - accuracy: 0.4909\nEpoch 48/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.3735 - accuracy: 0.5091\nEpoch 49/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.3459 - accuracy: 0.5091\nEpoch 50/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.3184 - accuracy: 0.4909\nEpoch 51/200\n1/1 [==============================] - 0s 16ms/step - loss: 2.2911 - accuracy: 0.5091\nEpoch 52/200\n1/1 [==============================] - 0s 15ms/step - loss: 2.2639 - accuracy: 0.5091\nEpoch 53/200\n1/1 [==============================] - 0s 12ms/step - loss: 2.2370 - accuracy: 0.5273\nEpoch 54/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.2104 - accuracy: 0.5273\nEpoch 55/200\n1/1 [==============================] - 0s 13ms/step - loss: 2.1842 - accuracy: 0.5273\nEpoch 56/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.1585 - accuracy: 0.5455\nEpoch 57/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.1333 - accuracy: 0.5636\nEpoch 58/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.1086 - accuracy: 0.5818\nEpoch 59/200\n1/1 [==============================] - 0s 13ms/step - loss: 2.0841 - accuracy: 0.5818\nEpoch 60/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.0598 - accuracy: 0.5818\nEpoch 61/200\n1/1 [==============================] - 0s 14ms/step - loss: 2.0356 - accuracy: 0.6000\nEpoch 62/200\n1/1 [==============================] - 0s 19ms/step - loss: 2.0114 - accuracy: 0.6000\nEpoch 63/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.9874 - accuracy: 0.6000\nEpoch 64/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.9635 - accuracy: 0.6000\nEpoch 65/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.9398 - accuracy: 0.6000\nEpoch 66/200\n1/1 [==============================] - 0s 17ms/step - loss: 1.9164 - accuracy: 0.6000\nEpoch 67/200\n1/1 [==============================] - 0s 17ms/step - loss: 1.8931 - accuracy: 0.6000\nEpoch 68/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.8701 - accuracy: 0.6000\nEpoch 69/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.8473 - accuracy: 0.6000\nEpoch 70/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.8247 - accuracy: 0.6000\nEpoch 71/200\n1/1 [==============================] - 0s 13ms/step - loss: 1.8023 - accuracy: 0.6000\nEpoch 72/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.7801 - accuracy: 0.6182\nEpoch 73/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.7580 - accuracy: 0.6182\nEpoch 74/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.7361 - accuracy: 0.6182\nEpoch 75/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.7143 - accuracy: 0.6182\nEpoch 76/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.6926 - accuracy: 0.6727\nEpoch 77/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.6711 - accuracy: 0.6727\nEpoch 78/200\n1/1 [==============================] - 0s 39ms/step - loss: 1.6496 - accuracy: 0.6727\nEpoch 79/200\n1/1 [==============================] - 0s 22ms/step - loss: 1.6283 - accuracy: 0.6727\nEpoch 80/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.6072 - accuracy: 0.6727\nEpoch 81/200\n1/1 [==============================] - 0s 17ms/step - loss: 1.5862 - accuracy: 0.6727\nEpoch 82/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.5653 - accuracy: 0.6909\nEpoch 83/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.5446 - accuracy: 0.6909\nEpoch 84/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.5241 - accuracy: 0.6909\nEpoch 85/200\n1/1 [==============================] - 0s 13ms/step - loss: 1.5037 - accuracy: 0.7091\nEpoch 86/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.4835 - accuracy: 0.7273\nEpoch 87/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.4635 - accuracy: 0.7455\nEpoch 88/200\n1/1 [==============================] - 0s 12ms/step - loss: 1.4436 - accuracy: 0.7455\nEpoch 89/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.4239 - accuracy: 0.7636\nEpoch 90/200\n1/1 [==============================] - 0s 12ms/step - loss: 1.4045 - accuracy: 0.7636\nEpoch 91/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.3852 - accuracy: 0.7636\nEpoch 92/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.3661 - accuracy: 0.7818\nEpoch 93/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.3472 - accuracy: 0.8000\nEpoch 94/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.3285 - accuracy: 0.8000\nEpoch 95/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.3100 - accuracy: 0.8000\nEpoch 96/200\n1/1 [==============================] - 0s 18ms/step - loss: 1.2917 - accuracy: 0.8000\nEpoch 97/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.2737 - accuracy: 0.8000\nEpoch 98/200\n1/1 [==============================] - 0s 13ms/step - loss: 1.2558 - accuracy: 0.8000\nEpoch 99/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.2382 - accuracy: 0.8000\nEpoch 100/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.2208 - accuracy: 0.8000\nEpoch 101/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.2035 - accuracy: 0.8000\nEpoch 102/200\n1/1 [==============================] - 0s 13ms/step - loss: 1.1865 - accuracy: 0.8000\nEpoch 103/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.1698 - accuracy: 0.8182\nEpoch 104/200\n1/1 [==============================] - 0s 16ms/step - loss: 1.1532 - accuracy: 0.8000\nEpoch 105/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.1368 - accuracy: 0.8000\nEpoch 106/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.1207 - accuracy: 0.8182\nEpoch 107/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.1047 - accuracy: 0.8182\nEpoch 108/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.0890 - accuracy: 0.8364\nEpoch 109/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.0735 - accuracy: 0.8545\nEpoch 110/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.0581 - accuracy: 0.8545\nEpoch 111/200\n1/1 [==============================] - 0s 15ms/step - loss: 1.0430 - accuracy: 0.8545\nEpoch 112/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.0281 - accuracy: 0.8545\nEpoch 113/200\n1/1 [==============================] - 0s 14ms/step - loss: 1.0134 - accuracy: 0.8545\nEpoch 114/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.9989 - accuracy: 0.8545\nEpoch 115/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.9846 - accuracy: 0.8545\nEpoch 116/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.9705 - accuracy: 0.8727\nEpoch 117/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.9565 - accuracy: 0.8727\nEpoch 118/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.9428 - accuracy: 0.8727\nEpoch 119/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.9293 - accuracy: 0.8727\nEpoch 120/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.9159 - accuracy: 0.8727\nEpoch 121/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.9028 - accuracy: 0.8727\nEpoch 122/200\n1/1 [==============================] - 0s 17ms/step - loss: 0.8898 - accuracy: 0.8727\nEpoch 123/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.8770 - accuracy: 0.8727\nEpoch 124/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.8644 - accuracy: 0.8727\nEpoch 125/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.8520 - accuracy: 0.8727\nEpoch 126/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.8397 - accuracy: 0.8727\nEpoch 127/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.8276 - accuracy: 0.8727\nEpoch 128/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.8158 - accuracy: 0.8727\nEpoch 129/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.8041 - accuracy: 0.8727\nEpoch 130/200\n1/1 [==============================] - 0s 18ms/step - loss: 0.7925 - accuracy: 0.8909\nEpoch 131/200\n1/1 [==============================] - 0s 20ms/step - loss: 0.7812 - accuracy: 0.8909\nEpoch 132/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.7700 - accuracy: 0.8909\nEpoch 133/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.7590 - accuracy: 0.8909\nEpoch 134/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.7481 - accuracy: 0.8909\nEpoch 135/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.7375 - accuracy: 0.8909\nEpoch 136/200\n1/1 [==============================] - 0s 16ms/step - loss: 0.7270 - accuracy: 0.8909\nEpoch 137/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.7166 - accuracy: 0.8909\nEpoch 138/200\n1/1 [==============================] - 0s 16ms/step - loss: 0.7064 - accuracy: 0.8909\nEpoch 139/200\n1/1 [==============================] - 0s 18ms/step - loss: 0.6964 - accuracy: 0.8909\nEpoch 140/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.6866 - accuracy: 0.8909\nEpoch 141/200\n1/1 [==============================] - 0s 16ms/step - loss: 0.6769 - accuracy: 0.8909\nEpoch 142/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.6673 - accuracy: 0.8909\nEpoch 143/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.6580 - accuracy: 0.8909\nEpoch 144/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.6487 - accuracy: 0.8909\nEpoch 145/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.6396 - accuracy: 0.8909\nEpoch 146/200\n1/1 [==============================] - 0s 12ms/step - loss: 0.6307 - accuracy: 0.8909\nEpoch 147/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.6219 - accuracy: 0.8909\nEpoch 148/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.6133 - accuracy: 0.8909\nEpoch 149/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.6048 - accuracy: 0.8909\nEpoch 150/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.5964 - accuracy: 0.8909\nEpoch 151/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.5882 - accuracy: 0.8909\nEpoch 152/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.5802 - accuracy: 0.8909\nEpoch 153/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.5722 - accuracy: 0.8909\nEpoch 154/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.5644 - accuracy: 0.8909\nEpoch 155/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.5568 - accuracy: 0.8909\nEpoch 156/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.5492 - accuracy: 0.8909\nEpoch 157/200\n1/1 [==============================] - 0s 12ms/step - loss: 0.5418 - accuracy: 0.8909\nEpoch 158/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.5346 - accuracy: 0.8909\nEpoch 159/200\n1/1 [==============================] - 0s 16ms/step - loss: 0.5274 - accuracy: 0.8909\nEpoch 160/200\n1/1 [==============================] - 0s 16ms/step - loss: 0.5204 - accuracy: 0.8909\nEpoch 161/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.5135 - accuracy: 0.8909\nEpoch 162/200\n1/1 [==============================] - 0s 18ms/step - loss: 0.5068 - accuracy: 0.8909\nEpoch 163/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.5001 - accuracy: 0.8909\nEpoch 164/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.4936 - accuracy: 0.8909\nEpoch 165/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.4872 - accuracy: 0.8909\nEpoch 166/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.4810 - accuracy: 0.8909\nEpoch 167/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.4748 - accuracy: 0.8909\nEpoch 168/200\n1/1 [==============================] - 0s 18ms/step - loss: 0.4688 - accuracy: 0.8909\nEpoch 169/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.4629 - accuracy: 0.8909\nEpoch 170/200\n1/1 [==============================] - 0s 16ms/step - loss: 0.4571 - accuracy: 0.8909\nEpoch 171/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.4514 - accuracy: 0.9091\nEpoch 172/200\n1/1 [==============================] - 0s 15ms/step - loss: 0.4459 - accuracy: 0.9091\nEpoch 173/200\n1/1 [==============================] - 0s 16ms/step - loss: 0.4404 - accuracy: 0.9091\nEpoch 174/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.4351 - accuracy: 0.9091\nEpoch 175/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.4298 - accuracy: 0.9091\nEpoch 176/200\n1/1 [==============================] - 0s 12ms/step - loss: 0.4247 - accuracy: 0.9091\nEpoch 177/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.4197 - accuracy: 0.9091\nEpoch 178/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.4148 - accuracy: 0.9091\nEpoch 179/200\n1/1 [==============================] - 0s 12ms/step - loss: 0.4099 - accuracy: 0.9091\nEpoch 180/200\n1/1 [==============================] - 0s 12ms/step - loss: 0.4052 - accuracy: 0.9091\nEpoch 181/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.4006 - accuracy: 0.9091\nEpoch 182/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3961 - accuracy: 0.9273\nEpoch 183/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.3917 - accuracy: 0.9273\nEpoch 184/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3874 - accuracy: 0.9273\nEpoch 185/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3831 - accuracy: 0.9273\nEpoch 186/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3790 - accuracy: 0.9273\nEpoch 187/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.3750 - accuracy: 0.9273\nEpoch 188/200\n1/1 [==============================] - 0s 17ms/step - loss: 0.3710 - accuracy: 0.9273\nEpoch 189/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.9273\nEpoch 190/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3633 - accuracy: 0.9273\nEpoch 191/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3596 - accuracy: 0.9273\nEpoch 192/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3560 - accuracy: 0.9273\nEpoch 193/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.3525 - accuracy: 0.9273\nEpoch 194/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3490 - accuracy: 0.9273\nEpoch 195/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.3456 - accuracy: 0.9273\nEpoch 196/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.3423 - accuracy: 0.9273\nEpoch 197/200\n1/1 [==============================] - 0s 17ms/step - loss: 0.3390 - accuracy: 0.9273\nEpoch 198/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.3359 - accuracy: 0.9273\nEpoch 199/200\n1/1 [==============================] - 0s 14ms/step - loss: 0.3328 - accuracy: 0.9273\nEpoch 200/200\n1/1 [==============================] - 0s 13ms/step - loss: 0.3297 - accuracy: 0.9273\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f0df412a7d0>"},"metadata":{}}]},{"cell_type":"code","source":"def prob_of_sentence(model,tokenizer,sentence):\n\n  # converting sentence into numerical form\n  encoded_sentence = tokenizer.texts_to_sequences([sentence])[0]\n  print(encoded_sentence)\n\n  # adding 0 as X<0>\n  encoded_sentence.insert(0,0)\n  print(encoded_sentence)\n\n  encoded_sentence = np.array(encoded_sentence).reshape((1,-1))\n  print(encoded_sentence)\n\n  prob = model.predict(encoded_sentence)\n  print(prob.shape)\n\n  probability = 1\n  for i in range(0,prob.shape[1] - 1):\n    probability *= prob[0,i,encoded_sentence[0,i+1]]\n  print(probability)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:56.196804Z","iopub.execute_input":"2022-05-05T06:13:56.197113Z","iopub.status.idle":"2022-05-05T06:13:56.206176Z","shell.execute_reply.started":"2022-05-05T06:13:56.197081Z","shell.execute_reply":"2022-05-05T06:13:56.205467Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"prob_of_sentence(model,tokenizer,\"fell down\")","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:13:57.885249Z","iopub.execute_input":"2022-05-05T06:13:57.885794Z","iopub.status.idle":"2022-05-05T06:13:58.038878Z","shell.execute_reply.started":"2022-05-05T06:13:57.885759Z","shell.execute_reply":"2022-05-05T06:13:58.038099Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"[]\n[0]\n[[0]]\n(1, 1, 32)\n1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"ii) Sentence Generation","metadata":{}},{"cell_type":"code","source":"def sample_all_wo_seed(model,tokenizer,n_words,vocab_length):\n  encoded_sentence = []\n  inp_text = ''\n\n  for i in range(n_words):\n    print('-'*50)\n    print('Input text : ', inp_text)\n\n    # converting sentence into numerical form\n    encoded_sentence = tokenizer.texts_to_sequences([inp_text])[0]\n\n    # adding 0 as X<0>\n    encoded_sentence.insert(0,0)\n    \n    encoded_sentence = np.array(encoded_sentence).reshape((1,-1))\n    print(\"For i : {} Encoded is : {}\".format(i, encoded_sentence))\n\n    if i == 0:\n      prob = model.predict(encoded_sentence, verbose= 0)\n      y_hat = 0\n      while y_hat == 0:\n        y_hat = np.random.choice(range(vocab_length),p=prob.ravel())\n        y_hat = np.array(y_hat).reshape((1,-1))\n      print(\"For i : {} yhat in if is : {}\".format(i, y_hat))\n\n    else:\n      prob = model.predict(encoded_sentence, verbose= 0)\n      print(prob.shape)\n      y_hat = np.append(y_hat,0)\n      y_hat = np.array(y_hat).reshape((1,-1))\n\n      while y_hat[0][i] == 0:\n        y_hat[0][i] = np.random.choice(range(vocab_length),p=prob[0][i].ravel())\n      print(\"For i : {} yhat in else is : {}\".format(i, y_hat))\n\n    output_word = \"\"\n    for word, index in tokenizer.word_index.items():\n      if index == y_hat[0][i]:\n        output_word = word\n        break\n    inp_text += output_word + ' '\n\n    print('-'*50)\n\n  return inp_text\nprint('\\n\\n' + color.BOLD + sample_all_wo_seed(model,tokenizer,3,vocab_length) + color.END)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:14:12.201237Z","iopub.execute_input":"2022-05-05T06:14:12.201504Z","iopub.status.idle":"2022-05-05T06:14:12.324909Z","shell.execute_reply.started":"2022-05-05T06:14:12.201474Z","shell.execute_reply":"2022-05-05T06:14:12.323722Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"--------------------------------------------------\nInput text :  \nFor i : 0 Encoded is : [[0]]\nFor i : 0 yhat in if is : [[16]]\n--------------------------------------------------\n--------------------------------------------------\nInput text :  dog \nFor i : 1 Encoded is : [[ 0 16]]\n(1, 2, 32)\nFor i : 1 yhat in else is : [[16 17]]\n--------------------------------------------------\n--------------------------------------------------\nInput text :  dog immediately \nFor i : 2 Encoded is : [[ 0 16 17]]\n(1, 3, 32)\nFor i : 2 yhat in else is : [[16 17 18]]\n--------------------------------------------------\n\n\n\u001b[1mdog immediately grabbed \u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"def sample_all_wo_seed_with_hp(model,tokenizer,n_words,vocab_length):\n  encoded_sentence = []\n  inp_text = ''\n\n  for i in range(n_words):\n    print('-'*50)\n    print('Input text : ', inp_text)\n\n    # converting sentence into numerical form\n    encoded_sentence = tokenizer.texts_to_sequences([inp_text])[0]\n\n    # adding 0 as X<0>\n    encoded_sentence.insert(0,0)\n    \n    encoded_sentence = np.array(encoded_sentence).reshape((1,-1))\n    print(\"For i : {} Encoded is : {}\".format(i, encoded_sentence))\n\n    if i == 0:\n      prob = model.predict(encoded_sentence, verbose= 0)\n      y_hat = 0\n      while y_hat == 0:\n        y_hat = np.random.choice(range(vocab_length),p=prob.ravel())\n        y_hat = np.array(y_hat).reshape((1,-1))\n      print(\"For i : {} yhat in if is : {}\".format(i, y_hat))\n\n    else:\n      prob = model.predict(encoded_sentence, verbose= 0)\n      print(prob.shape)\n      y_hat = np.append(y_hat,0)\n      y_hat = np.array(y_hat).reshape((1,-1))\n\n      # while y_hat[0][i] == 0:\n      \n      y_hat[0][i] = np.argmax(prob[0][i].ravel()[1:] , axis=0)\n      print(\"For i : {} yhat in else is : {}\".format(i, y_hat))\n\n    output_word = \"\"\n    for word, index in tokenizer.word_index.items():\n      if index == y_hat[0][i]:\n        output_word = word\n        break\n    inp_text += output_word + ' '\n\n    print('-'*50)\n\n  return inp_text\nprint('\\n\\n' + color.BOLD + sample_all_wo_seed_with_hp(model,tokenizer,5,vocab_length) + color.END)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T06:14:34.589171Z","iopub.execute_input":"2022-05-05T06:14:34.589442Z","iopub.status.idle":"2022-05-05T06:14:34.811611Z","shell.execute_reply.started":"2022-05-05T06:14:34.589393Z","shell.execute_reply":"2022-05-05T06:14:34.810851Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"--------------------------------------------------\nInput text :  \nFor i : 0 Encoded is : [[0]]\nFor i : 0 yhat in if is : [[2]]\n--------------------------------------------------\n--------------------------------------------------\nInput text :  he \nFor i : 1 Encoded is : [[0 2]]\n(1, 2, 32)\nFor i : 1 yhat in else is : [[ 2 16]]\n--------------------------------------------------\n--------------------------------------------------\nInput text :  he dog \nFor i : 2 Encoded is : [[ 0  2 16]]\n(1, 3, 32)\nFor i : 2 yhat in else is : [[ 2 16 17]]\n--------------------------------------------------\n--------------------------------------------------\nInput text :  he dog immediately \nFor i : 3 Encoded is : [[ 0  2 16 17]]\n(1, 4, 32)\nFor i : 3 yhat in else is : [[ 2 16 17  2]]\n--------------------------------------------------\n--------------------------------------------------\nInput text :  he dog immediately he \nFor i : 4 Encoded is : [[ 0  2 16 17  2]]\n(1, 5, 32)\nFor i : 4 yhat in else is : [[ 2 16 17  2 18]]\n--------------------------------------------------\n\n\n\u001b[1mhe dog immediately he grabbed \u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}